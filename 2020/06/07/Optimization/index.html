
<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Optimization | Study notes</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="1. Stochastic Gradient Descent (SGD)  GD is infeasible for large datasets so we need SGD.  \(i\) is a random index between 1 and n: \[ w^t&#x3D;w^{t-1}-\eta_tg_{t-1}, \] where \(w^t\) is the weight at iter">
<meta property="og:type" content="article">
<meta property="og:title" content="Optimization">
<meta property="og:url" content="http://sunyinge.github.io/2020/06/07/Optimization/index.html">
<meta property="og:site_name" content="Study notes">
<meta property="og:description" content="1. Stochastic Gradient Descent (SGD)  GD is infeasible for large datasets so we need SGD.  \(i\) is a random index between 1 and n: \[ w^t&#x3D;w^{t-1}-\eta_tg_{t-1}, \] where \(w^t\) is the weight at iter">
<meta property="og:image" content="http://sunyinge.github.io/images/SDG.png">
<meta property="og:image" content="http://sunyinge.github.io/images/Momentum.png">
<meta property="og:image" content="http://sunyinge.github.io/images/momentumExplan.png">
<meta property="og:image" content="http://sunyinge.github.io/images/nesterovExplan.png">
<meta property="article:published_time" content="2020-06-08T05:24:21.000Z">
<meta property="article:modified_time" content="2020-06-09T01:06:23.289Z">
<meta property="article:author" content="Yinge Sun">
<meta property="article:tag" content="DL">
<meta property="article:tag" content="Optimization">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://sunyinge.github.io/images/SDG.png">
  
    <link rel="alternative" href="/atom.xml" title="Study notes" type="application/atom+xml">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 4.2.1"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        
          <a id="nav-github" class="nav-icon" href="https://github.com/sunyinge" target="_blank" rel="noopener"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Study notes</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Hello!</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
      <a class="main-nav-link st-search-show-outputs">Search</a>
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-Optimization" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2020/06/07/Optimization/" class="article-date">
  <time datetime="2020-06-08T05:24:21.000Z" itemprop="datePublished">2020-06-07</time>
</h3>
    
  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Optimization
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h3 id="stochastic-gradient-descent-sgd">1. Stochastic Gradient Descent (SGD)</h3>
<ul>
<li>GD is infeasible for <strong>large datasets</strong> so we need SGD.</li>
</ul>
<p><span class="math inline">\(i\)</span> is a random index between 1 and n: <span class="math display">\[
w^t=w^{t-1}-\eta_tg_{t-1},
\]</span> where <span class="math inline">\(w^t\)</span> is the weight at iteration t, <span class="math inline">\(\eta\)</span> is the learning rate at iteration t and <span class="math inline">\(g_t=\nabla L(w^t; x_i, y_i)\)</span> is the gradient of <span class="math inline">\(i\)</span>th example's loss function with respect to <span class="math inline">\(w^t\)</span>. The <span class="math inline">\(w^t\)</span>, <span class="math inline">\(g_t\)</span> could be a scalar, vector or matrix with the same size.</p>
<h3 id="mini-batch-gradient-descent">2. Mini-batch Gradient Descent</h3>
<p><span class="math inline">\(i_1,\ldots,i_m\)</span> are random indices between 1 and n: <span class="math display">\[
w^t=w^{t-1}-\eta_t\sum_{j=1}^mg^{i_j}_{t-1},
\]</span> where <span class="math inline">\(g^{i_j}_t=\sum_{j=1}^m\nabla L(w^t; x_{i_j}, y_{i_j})\)</span> is the gradient of <span class="math inline">\(i_1\)</span>th to <span class="math inline">\(i_m\)</span>th example's loss function with respect to <span class="math inline">\(w^t\)</span>.</p>
<ul>
<li>Mini-batch GD is <strong>less noisy</strong> than SGD.</li>
</ul>
<h3 id="momentum">3. Momentum</h3>
<ul>
<li><p>Oscillation is not good for optimization, as shown in the graph on the left.</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><img src="/images/SDG.png" alt="" style="zoom:50%;" /></th>
<th style="text-align: center;"><img src="/images/Momentum.png" alt="" style="zoom:52%;" /></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><em>SGD Oscillation</em></td>
<td style="text-align: center;"><strong><em>Momentum</em></strong></td>
</tr>
</tbody>
</table>
<a id="more"></a>
<p>momentum <span class="math inline">\(h_t\)</span>: <span class="math display">\[
h_t=\alpha h_{t-1}+\eta g_{t-1}, \ h_0=0\\
w^t=w^{t-1}-h_t
\]</span></p>
<ul>
<li>accumulates values along dimentsion where the gradients have the same sign while cancels each other along dimensions where the gradients have different signs. So <span class="math inline">\(h_t\)</span> cancels some coordinates that lead to oscillation of gradients, <strong>as the graph on the right shows</strong>.</li>
<li>tends to make the weights move in the same direction as on previous steps since essentially <span class="math inline">\(h_t=\eta g_{t-1}+\alpha \eta g_{t-2}+\alpha^2\eta g_{t-3}+\cdots+\alpha^{t-1}\eta g_0\)</span> where usually <span class="math inline">\(\boldsymbol{\alpha=0.9}\)</span> controls how much the local gradient <strong>influences long term movement</strong>.</li>
</ul></li>
</ul>
<h3 id="nesterov-momentum">4. Nesterov Momentum</h3>
<p>Nesterov momentum is a simple extension to normal momentum: <span class="math display">\[
h_t=\alpha h_{t-1}+\eta\nabla L(w^{t-1}-\alpha h_{t-1}), \ h_0=0\\
w^t=w^{t-1}-h_t
\]</span> where the gradient term <span class="math inline">\(\nabla L(w^{t-1}-\alpha h_{t-1})\)</span> is not computed from the currect position <span class="math inline">\(w^{t-1}\)</span> but from a new point <span class="math inline">\(w^{t-1}-\alpha h_{t-1}\)</span>.</p>
<p>This helps because</p>
<ul>
<li>if the gradient term <span class="math inline">\(g_t=\nabla L(w^t)\)</span> always points in the right direction, the momentum term <span class="math inline">\(h_t\)</span> may not. If the momentum term points in the wrong direction, the gradient <span class="math inline">\(\nabla L(w^{t-1}-\alpha h_{t-1})\)</span> can still &quot;go back&quot; and correct it in the <strong>same</strong> update step.</li>
<li>if the momentum term <span class="math inline">\(h_t\)</span> always points in the right direction, it is just one step ahead the normal momentum.</li>
</ul>
<p>Detailed explanation can be found <a href="https://dominikschmidt.xyz/nesterov-momentum/" target="_blank" rel="noopener">here</a>, which can be summarized by the two graphs below (represented by different parameters ):</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><img src="/images/momentumExplan.png" alt="" style="zoom:30%;" /></th>
<th style="text-align: center;"><img src="/images/nesterovExplan.png" alt="" style="zoom:30%;" /></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><em>Momentum</em></td>
<td style="text-align: center;"><em>Nesterov Momentum</em></td>
</tr>
</tbody>
</table>
<ul>
<li>Nesterov momentum achieves <strong>better performance</strong> than momentum in practice.</li>
</ul>
<h3 id="adagrad">5. AdaGrad</h3>
<p>We would like the learning rate to be large at the beginning and then gradually decreases so that it won't miss the minimum, such as <span class="math inline">\(\eta_t = \frac{\eta}{\sqrt{t}}\)</span>. But the problem with this learning rate is that it does not change with different parameters. We hope the learning rate to <strong>update adaptively</strong> in the sense that the parameters move a small step when the corresponding previous gradients are large and move a large step when small, which makes the learning rate to be <span class="math inline">\(\frac{\eta_t}{\sqrt{\frac{1}{t}\sum_{i=0}^{t-1}g_i^2}}\)</span>. As such, <span class="math display">\[
w^t=w^{t-1}-\frac{\eta_t}{\sqrt{\frac{1}{t}\sum_{i=0}^{t-1}g_i^2}}g_{t-1}=w^{t-1}-\frac{\eta}{\sqrt{\sum_{i=0}^{t-1}g_i^2}}g_{t-1}
\]</span> To avoid zero denominator, we add a small number <span class="math inline">\(\epsilon\)</span> to the denominator so that <span class="math display">\[
G^t=G^{t-1}+g_{t-1}^2,\ G^0=0\\
w^t=w^{t-1}-\frac{\eta}{\sqrt{G^{t}+\epsilon}}g_{t-1}
\]</span></p>
<h3 id="rmsprop">6. RMSprop</h3>
<ul>
<li>The problem of AdaGrad is that it may lead to <strong>early stop</strong> if <span class="math inline">\(G^t\)</span> is too large.</li>
</ul>
<p>So in RMSprop, <span class="math display">\[
G^t=\alpha G^{t-1}+(1-\alpha)g_{t-1}^2,\ G^0=0\\
w^t=w^{t-1}-\frac{\eta}{\sqrt{G^{t}+\epsilon}}g_{t-1},
\]</span> where <span class="math inline">\(\alpha\)</span> is the decay parameter and usually is set to 0.9.</p>
<p>If we rewrite <span class="math inline">\(G^t=(1-\alpha)g_{t-1}^2+\alpha(1-\alpha)g_{t-2}^2+\alpha^2(1-\alpha)g_{t-3}+\cdots+\alpha^{t-1}(1-\alpha)g_0^2\)</span>, we found that the long term influences of gradients are small and <span class="math inline">\(G^t\)</span> is mainly determined by recent gradients.</p>
<h3 id="adam">7. Adam</h3>
<p>Adam combines strength of <strong>moment methods</strong> and <strong>adaptive learning rate methods</strong> so as to smooth gradients and speed up convergence at the same time. <span class="math display">\[
\nu^t=\frac{\beta_2 \nu^{t-1}+(1-\beta_2)g_{t-1}^2}{1-\beta_2^t},\ \nu^0=0\\
m^t=\frac{\beta_1 m^{t-1}+(1-\beta_1)g_{t-1}}{1-\beta_1^t},\ m^0=0\\
w^t=w^{t-1}-\frac{\eta}{\sqrt{\nu^{t}}+\epsilon}m_{t},
\]</span></p>
<ul>
<li><a href="https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c" target="_blank" rel="noopener">Adam</a> is the latest trend in deep learning optimization.</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DL/" rel="tag">DL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Optimization/" rel="tag">Optimization</a></li></ul>

        <a data-url="http://sunyinge.github.io/2020/06/07/Optimization/" data-id="ckck2ey6v0009io3xfwe39vjn" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/06/07/Measure-of-accuracy/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Measure of accuracy
        
      </div>
    </a>
  
  
    <a href="/2020/06/07/Set-up/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Set up</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/07/12/All-pairs-shortest-paths/">All-pairs shortest paths</a>
          </li>
        
          <li>
            <a href="/2020/07/11/Single-source-shortest-path/">Single-source shortest path</a>
          </li>
        
          <li>
            <a href="/2020/06/29/Dynamic-programming/">Dynamic programming</a>
          </li>
        
          <li>
            <a href="/2020/06/24/Python/">Python</a>
          </li>
        
          <li>
            <a href="/2020/06/23/Probabilistic-graphic-models-for-sequence-tagging/">Probabilistic graphic models for sequence tagging</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithm/" rel="tag">Algorithm</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DL/" rel="tag">DL</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Installation/" rel="tag">Installation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ML/" rel="tag">ML</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/" rel="tag">NLP</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Optimization/" rel="tag">Optimization</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">July 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">June 2020</a><span class="archive-list-count">10</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Yinge Sun<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
  <a href="#search" class="mobile-nav-link st-search-show-outputs">Search</a>
</nav>

  
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    menuSettings: {
      zoom: "None"
    },
    showMathMenu: false,
    jax: ["input/TeX","output/CommonHTML"],
    extensions: ["tex2jax.js"],
    TeX: {
      extensions: ["AMSmath.js","AMSsymbols.js"],
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
  });
</script>

<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.6.1/MathJax.js"></script>



<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>


</div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
